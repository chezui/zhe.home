[
  {
    "objectID": "cv.html",
    "href": "cv.html",
    "title": "CV",
    "section": "",
    "text": "Category\nDetails\n\n\n\n\nProgramming\nPython, SQL, R, Scala, C/C++\n\n\nDomains\nRecommender Systems, Content Quality and Understanding, Multi-sided Marketplace, Ads & Developer Ecosystem\n\n\nQuantitative\nMachine Learning, MLOps, Statistics, Optimization, Large-scale Data Analysis, Causal Inference, Design of Experiments, Large Language Models, Data Modeling/ETL\n\n\nTechnologies\nPyTorch, Dataswarm/Airflow, Spark, Presto, Hive, Alerts/Monitoring, Dashboards, R Tidyverse (ggplot2, dplyr, tidymodels), Git/Mercurial, \\LaTeX"
  },
  {
    "objectID": "cv.html#skills",
    "href": "cv.html#skills",
    "title": "CV",
    "section": "",
    "text": "Category\nDetails\n\n\n\n\nProgramming\nPython, SQL, R, Scala, C/C++\n\n\nDomains\nRecommender Systems, Content Quality and Understanding, Multi-sided Marketplace, Ads & Developer Ecosystem\n\n\nQuantitative\nMachine Learning, MLOps, Statistics, Optimization, Large-scale Data Analysis, Causal Inference, Design of Experiments, Large Language Models, Data Modeling/ETL\n\n\nTechnologies\nPyTorch, Dataswarm/Airflow, Spark, Presto, Hive, Alerts/Monitoring, Dashboards, R Tidyverse (ggplot2, dplyr, tidymodels), Git/Mercurial, \\LaTeX"
  },
  {
    "objectID": "cv.html#industry-experience",
    "href": "cv.html#industry-experience",
    "title": "CV",
    "section": "Industry Experience",
    "text": "Industry Experience\n\nSenior Data Scientist, Snap (2024‚Äìpresent) | Seattle, WA\n\nRanking: Driving Improvements in Recommended Content on Snapchat: Short Video Feed, Discover\nContent Quality and Understanding: Signals, Models and Methodology for Improving Content Quality on Snapchat.\nStrategic Insights: Recommendations to CEO, CFO, VPs and other senior leadership on product direction and business impact.\n\n\n\nData Scientist, Meta (2017‚Äì2023) | Seattle, WA\n\nImproved Advertiser Reliability Metric by 50% with Real-time Machine Learning: End-to-end development, deployment, and monitoring of GBDT models to predict API requests likely to OOM and timeout, dispatching expensive requests to an async tier. Reduced daily advertiser API errors from 6‚Äì7% to 3%.\nReduced Ads API Query Latency (p99) by 10%: Applied observational causal inference via propensity score modeling and regression discontinuity to identify features most impactful for slow queries and prioritized fixes with SWE teams.\nPredicted Errors Blocking Advertisers: Analyzed and modeled Ads Manager session data to identify error patterns predictive of uncompleted ad creation; findings informed roadmap planning and documentation improvements.\nDeveloped Framework to Estimate Revenue Impact of API Errors: Quantified ad spend loss due to campaign failures to evaluate business impact of SEVs and regressions.\nPersonalization & Recommender Systems: Led hypothesis-driven analyses and experiments to enhance Facebook App Navigation and Groups Ranking using two-tower neural network models.\n\n\n\nData Scientist, Bell Canada (2015‚Äì2017) | Toronto, ON, Canada\n\nCustomer Journey Analytics: Designed and implemented an Apache Spark algorithm to model event data for funnel analysis and pattern mining; used derived features to improve churn prediction lift by 20%.\nCustomer Churn Prediction: Built Random Forest, GBDT, neural network, GLM, and ensemble models to score churn risk and inform targeted retention offers.\nImproved Retail Store Internet Speed 10√ó: Identified outdated connections in demo units, built a business case to upgrade to fiber internet, reducing new customer signup time by 50%.\n\n\n\nResearch Assistant, University of Toronto (2012‚Äì2015) | Toronto, ON, Canada\n\nResource Allocation in Backhaul-Constrained Small Cell Networks: Developed distributed algorithms in MATLAB and Python for cooperative resource allocation in 5G networks. Published and presented at CISS 2014 (link).\n\n\n\nInternships (2007‚Äì2012)\n\nApple (2011), Magnum Semiconductor (2011), ON Semiconductor (2008‚Äì2010): Projects in signal processing (audio, biomedical), machine learning, and embedded systems."
  },
  {
    "objectID": "cv.html#education",
    "href": "cv.html#education",
    "title": "CV",
    "section": "Education",
    "text": "Education\n\nMasters of Applied Science, Electrical Engineering, University of Toronto (2012‚Äì2015) Thesis: Resource Allocation in Backhaul Constrained Small-Cell Networks, Grade A\nBachelor of Applied Science, Electrical Engineering, University of Waterloo (2007‚Äì2012), Honors First Class\nInternational Exchange, Electrical Engineering, National University of Singapore (2010)"
  },
  {
    "objectID": "work/2025-07-07-inverse-propensity-score-weight/index.html",
    "href": "work/2025-07-07-inverse-propensity-score-weight/index.html",
    "title": "[WIP] Selection Bias in Recommender Systems",
    "section": "",
    "text": "The setup: we have a recommender system that serves items to users that we believe they will find engaging, we then log and analyze the engagement data to find insights for improvements. We find that videos about red pandas get 10x more watch time and 5x more shares than videos about model airplanes.\nWhen we use engagement logs from a recommender systems, we need to address the issue of selection bias. Using the engagement log data naively to make design and business decisions is not a good idea due to two major sources of recommendation bias:\n\nSelection Bias: Users only engage with items that we recommend them that we serve based on our ranking models expecting these items will be engaging (watch time, clicks, shares etc.).\nPositional Bias: Users are more likely to engage with items that are placed higher in the feed (e.g.¬†first few items in the feed).\n\n\n\n\n\n\ngraph LR\n    user[User] --&gt; recommender[Recommender]\n    recommender --&gt; exposure[Exposure]\n    exposure --&gt; action[Action]\n    action --&gt; log[Log]"
  },
  {
    "objectID": "work/2025-07-07-inverse-propensity-score-weight/index.html#problem-statement",
    "href": "work/2025-07-07-inverse-propensity-score-weight/index.html#problem-statement",
    "title": "[WIP] Selection Bias in Recommender Systems",
    "section": "",
    "text": "The setup: we have a recommender system that serves items to users that we believe they will find engaging, we then log and analyze the engagement data to find insights for improvements. We find that videos about red pandas get 10x more watch time and 5x more shares than videos about model airplanes.\nWhen we use engagement logs from a recommender systems, we need to address the issue of selection bias. Using the engagement log data naively to make design and business decisions is not a good idea due to two major sources of recommendation bias:\n\nSelection Bias: Users only engage with items that we recommend them that we serve based on our ranking models expecting these items will be engaging (watch time, clicks, shares etc.).\nPositional Bias: Users are more likely to engage with items that are placed higher in the feed (e.g.¬†first few items in the feed).\n\n\n\n\n\n\ngraph LR\n    user[User] --&gt; recommender[Recommender]\n    recommender --&gt; exposure[Exposure]\n    exposure --&gt; action[Action]\n    action --&gt; log[Log]"
  },
  {
    "objectID": "work/2025-07-07-inverse-propensity-score-weight/index.html#quarto-features",
    "href": "work/2025-07-07-inverse-propensity-score-weight/index.html#quarto-features",
    "title": "[WIP] Selection Bias in Recommender Systems",
    "section": "Quarto Features",
    "text": "Quarto Features\nQuarto supports a variety of features including citations, cross-references, and more. Here‚Äôs an example of a citation:\n\n‚ÄúQuarto is a next-generation open-source scientific and technical publishing system.‚Äù [@quarto]"
  },
  {
    "objectID": "work/2025-07-07-inverse-propensity-score-weight/index.html#references",
    "href": "work/2025-07-07-inverse-propensity-score-weight/index.html#references",
    "title": "[WIP] Selection Bias in Recommender Systems",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "work/2025-07-07-inverse-propensity-score-weight/index.html#ideas",
    "href": "work/2025-07-07-inverse-propensity-score-weight/index.html#ideas",
    "title": "[WIP] Selection Bias in Recommender Systems",
    "section": "Ideas",
    "text": "Ideas\nPerfect ‚Äî a blog post forces clarity and accessibility. You want it to feel like: üëâ ‚ÄúHere‚Äôs the real problem. Here‚Äôs why naive approaches fail. Here‚Äôs how smart people tackle it (and the limits).‚Äù\nHere‚Äôs a crisp outline I‚Äôd recommend for your blog post ‚ÄúSelection Bias in Recommender System Engagement Logs‚Äù ‚Äî designed to teach your reader and yourself:\n\n\nüìå Title:\nSelection Bias in Recommender System Engagement Logs: The Hidden Trap in Offline Evaluation (and How to Fight It)\n\n\n\nüîπ Intro (set the hook)\n\nStart with a real-world example: ‚ÄúImagine you‚Äôre testing a new recommender model offline. The logs say item A has double the click rate of item B ‚Äî so you boost A. But when you launch, engagement drops. What happened?‚Äù\nState the thesis: Offline metrics can lie because of selection bias. This post explains why, and what to do about it.\n\n\n\n\nüîπ The core problem: Why your engagement logs are biased\n\nDiagram: user ‚Üí recommender ‚Üí exposure ‚Üí action ‚Üí log\nExplain exposure bias, positional bias, user bias.\nShow (or describe) a simple example: e.g.¬†top slot always gets 10x clicks, no matter what you put there.\n\n\n\n\nüîπ Where this hurts us\n\nOffline evaluation: why naive click rates overestimate or underestimate true performance\nTraining models: why we learn the wrong preferences\nMarketplace fairness: why some items or creators stay buried\n\n\n\n\nüîπ The statistical fix: Inverse Propensity Score Weighting\n\nIntuition: ‚ÄúAdjust for how likely an item was to be shown in the first place.‚Äù\nShow formula: unbiased estimator of engagement\nExample: walk through toy data (small table: item, propensity, click, IPS weight)\nDiscuss variance: why small propensities are dangerous\nMitigation: clipping, self-normalized IPS\n\n\n\n\nüîπ Beyond IPS\n\nDoubly robust estimators\nDirect modeling / causal models\nDesign for exploration (logging randomization)\n\n\n\n\nüîπ Practical guidance\n\nIf you don‚Äôt know the logging propensities, what can you do?\nWhen is IPS worth using, when is it overkill?\nHow to design your system to reduce selection bias at the source\n\n\n\n\nüîπ Conclusion\n\nReinforce takeaway: ‚ÄúLogs don‚Äôt tell you the full truth. Selection bias is the silent killer of offline evaluation ‚Äî but with the right tools, you can fight it.‚Äù\n\n\n\n\n‚úÖ Why this will deepen your learning\nYou‚Äôll have to:\n\nArticulate the problem clearly\nDo the math and make it accessible\nCode an example (even if just for yourself)\nThink critically about trade-offs\n\n\nIf you like, I can help you: üëâ draft the intro hook üëâ sketch the toy example data + math üëâ help you build a Quarto / Jupyter notebook to embed in your blog\nAre you thinking of publishing on Medium, personal site, or somewhere else?"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Zhe Cui (Â¥îÂì≤)",
    "section": "",
    "text": "Pronunciation üó£ Juh Sway\n\n\n\nHello, I‚Äôm Zhe Cui (Â¥îÂì≤). I build things, analyze things, and occasionally break things in the pursuit of making them better.\nI like problems that don‚Äôt have obvious answers. I like asking why something works, why it doesn‚Äôt, and how it could be better. This blog is where I think out loud‚Äîabout AI, data science, engineering, and the occasional side project.\nIf any of that sounds interesting, stick around.\nI‚Äôm always interested in connecting with like minded folks: feel free to reach me on X and LinkedIn."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Zhe Cui (Â¥îÂì≤)",
    "section": "",
    "text": "Pronunciation üó£ Juh Sway\n\n\n\nHello, I‚Äôm Zhe Cui (Â¥îÂì≤). I build things, analyze things, and occasionally break things in the pursuit of making them better.\nI like problems that don‚Äôt have obvious answers. I like asking why something works, why it doesn‚Äôt, and how it could be better. This blog is where I think out loud‚Äîabout AI, data science, engineering, and the occasional side project.\nIf any of that sounds interesting, stick around.\nI‚Äôm always interested in connecting with like minded folks: feel free to reach me on X and LinkedIn."
  }
]